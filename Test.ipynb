{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Test.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Rp3kU3j9TQmk","colab_type":"code","outputId":"e425ae08-6e40-46d2-f621-7067d36bc96b","executionInfo":{"status":"ok","timestamp":1574538663328,"user_tz":-120,"elapsed":10049,"user":{"displayName":"Mina 3.Melek","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAWTZeaXL6pBID15v903jVhJLIYLmIkX1FgP2jL=s64","userId":"10444321559887690581"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import sys\n","import os\n","import time\n","import copy\n","import pickle\n","import random\n","from random import shuffle \n","import matplotlib.pyplot as plt\n","from scipy import spatial\n","\n","from sklearn.manifold import TSNE\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, classification_report\n","# from keras.utils.np_utils import to_categorical\n","from gensim.models import Word2Vec\n","from multiprocessing import cpu_count\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n","from torch.autograd import Variable\n","# from torchtext.data import Example\n","# import torchtext\n","\n","torch.manual_seed(10)\n","\n","\n","%load_ext autoreload\n","%autoreload 2\n","this = sys.modules[__name__]"],"execution_count":0,"outputs":[{"output_type":"stream","text":["The autoreload extension is already loaded. To reload it, use:\n","  %reload_ext autoreload\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cOfOFTBNSu1U","colab_type":"code","colab":{}},"source":["def read_preTrained(file_name):\n","    with open(file_name,'r') as f:\n","        word_vocab = set() # not using list to avoid duplicate entry\n","        word2vector = {}\n","        for line in f:\n","            line_ = line.strip() #Remove white space\n","            words_Vec = line_.split()\n","            if len(words_Vec) > 301:\n","                continue\n","            try:\n","                word_vocab.add(words_Vec[0])\n","                word2vector[words_Vec[0]] = np.array(words_Vec[1:],dtype=float)\n","            except ValueError:\n","                continue\n","    return word_vocab,word2vector\n","\n","def read_numpy_files():\n","    \"\"\"Instead of running the entire pipeline at all times.\"\"\"\n","    filename = os.path.join(curDir, 'data', 'train_test_data.dat') ##@\n","    with open(filename, 'rb') as handle:\n","        x_train = pickle.load(handle)\n","        y_train = pickle.load(handle)\n","        x_test = pickle.load(handle)\n","        y_test = pickle.load(handle)\n","        int_category = pickle.load(handle)\n","        category_int = pickle.load(handle)\n","\n","    return (x_train, y_train), (x_test, y_test), int_category, category_int\n","\n","def seed_everything(seed=10):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xdlj0K02MVhO","colab_type":"code","outputId":"0f98837f-6a25-4b89-8a07-e1b894832216","executionInfo":{"status":"ok","timestamp":1574538663330,"user_tz":-120,"elapsed":10021,"user":{"displayName":"Mina 3.Melek","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAWTZeaXL6pBID15v903jVhJLIYLmIkX1FgP2jL=s64","userId":"10444321559887690581"}},"colab":{"base_uri":"https://localhost:8080/","height":221}},"source":["document_max_num_words = 15\n","emb_dim = 300\n","firstTime = False\n","cache = True\n","reuters = False\n","# reader.generate_categories(reuters)\n","# class_names = reader.categories # works\n","print('reading data...')\n","print('# of dimensions is: ', emb_dim)\n","(x_train, y_train), (x_test, y_test), int_category, category_int = read_numpy_files()\n","# vocabulary = np.insert(np.load('./data/vocabulary.npy'), 0, '')\n","vocabulary = np.load('./data/vocabulary.npy')\n","categories = np.load('./data/categories.npy')\n","print('Training data size: ', x_train.shape, y_train.shape)\n","print('Testing data size: ', x_test.shape, y_test.shape)\n","print('Vocabulary size: ', len(vocabulary))\n","print('Categories: ', len(categories), categories)\n","# print(int_category)\n","# word_to_ix = {word: i for i, word in enumerate(vocabulary)}\n","# bad_score = ['COLLEGE', 'ENVIRONMENT', 'FIFTY', 'HEALTHY LIVING', 'LATINO VOICES', 'MONEY', 'PARENTS', 'TASTE', 'WORLD NEWS']\n","# x_train = reader.vectorize_idx(x_train, word_to_ix, document_max_num_words)\n","# y_train = np.array(list(y_train.values()))\n","# x_test = reader.vectorize_idx(x_test, word_to_ix, document_max_num_words)\n","# y_test = np.array(list(y_test.values()))\n","# reader.save_data(x_train, y_train, x_test, y_test, int_category, category_int)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["reading data...\n","# of dimensions is:  300\n","Training data size:  (160682, 15) (160682, 40)\n","Testing data size:  (40171, 15) (40171, 40)\n","Vocabulary size:  55618\n","Categories:  40 ['ARTS' 'ARTS & CULTURE' 'BLACK VOICES' 'BUSINESS' 'COLLEGE' 'COMEDY'\n"," 'CRIME' 'CULTURE & ARTS' 'DIVORCE' 'EDUCATION' 'ENTERTAINMENT'\n"," 'ENVIRONMENT' 'FIFTY' 'FOOD & DRINK' 'GOOD NEWS' 'GREEN' 'HEALTHY LIVING'\n"," 'HOME & LIVING' 'IMPACT' 'LATINO VOICES' 'MEDIA' 'MONEY' 'PARENTING'\n"," 'PARENTS' 'POLITICS' 'QUEER VOICES' 'RELIGION' 'SCIENCE' 'SPORTS' 'STYLE'\n"," 'STYLE & BEAUTY' 'TASTE' 'TECH' 'TRAVEL' 'WEDDINGS' 'WEIRD NEWS'\n"," 'WELLNESS' 'WOMEN' 'WORLD NEWS' 'WORLDPOST']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"E5vaklRFXriJ","outputId":"e8f85b09-ece2-4d34-98bd-208065c1a81c","executionInfo":{"status":"ok","timestamp":1574538664567,"user_tz":-120,"elapsed":11236,"user":{"displayName":"Mina 3.Melek","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAWTZeaXL6pBID15v903jVhJLIYLmIkX1FgP2jL=s64","userId":"10444321559887690581"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# vocab, w2v = read_preTrained(\"./model/glove_files/glove.840B.300d.txt\")\n","# print(\"Total Words in DataSet:\",len(vocab))\n","# emb_dim = w2v[list(vocab)[0]].shape[0]\n","# matrix_len = len(vocabulary)\n","# weights_matrix = np.zeros((matrix_len, emb_dim))\n","# words_not_found = 0\n","# n_words = []\n","\n","# for i, word in enumerate(vocabulary):\n","#     try: \n","#         weights_matrix[i] = w2v[word]\n","#     except KeyError:\n","#         weights_matrix[i] = np.random.normal(scale=0.6, size=(emb_dim, ))\n","#         words_not_found += 1\n","#         n_words.append(word)\n","\n","# print('words not found:', words_not_found)\n","# print('random embedded words percentage = %.2f%%'%(words_not_found/(matrix_len)*100))\n","# import gc\n","# w2v.clear() \n","# del w2v, vocab\n","# gc.collect()\n","# len(n_words)\n","# n_words[:50]\n","# np.savez_compressed('./data/weights_matrix_840B', weights_matrix)\n","weights_matrix = np.load('./data/weights_matrix_840B.npz')['arr_0']\n","weights_matrix = torch.tensor(weights_matrix, dtype=torch.float64)\n","print(weights_matrix.size())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["torch.Size([55618, 300])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qSINXT7dQfKz","colab_type":"code","colab":{}},"source":["class LSTMTopic(nn.Module):\n","\n","    def __init__(self, weights_matrix, lstm_out, dense_out, num_categories, noEmbTrain=True, uselast=True, maxpool=False):\n","        super(LSTMTopic, self).__init__()\n","        self.hidden_dim = lstm_out[1]\n","        self.uselast = uselast\n","        self.maxpool = maxpool\n","        num_embeddings, embedding_dim = weights_matrix.size()\n","        self.embedding = nn.Embedding.from_pretrained(weights_matrix, freeze=noEmbTrain)\n","        #self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n","\n","        # The LSTM takes word embeddings as inputs, and outputs hidden states\n","        # with dimensionality hidden_dim.\n","        self.lstm1 = nn.LSTM(embedding_dim, self.hidden_dim , 3, batch_first=True, dropout=0.5)\n","        self.lstm2 = nn.LSTM(embedding_dim, self.hidden_dim , 1, batch_first=True)\n","        # The linear layer that maps from hidden state space to tag space\n","        # self.dense= nn.Linear(self.hidden_dim , dense_out)\n","        # self.relu = nn.ReLU()\n","        self.drop = nn.Dropout(0.5)\n","        self.out = nn.Linear(self.hidden_dim , num_categories)\n","        self.softmax = nn.Softmax(dim=1)\n","\n","    def forward(self, inputs):\n","        x = self.embedding(inputs)\n","        x, (h, c) = self.lstm2(x.float())\n","        #x, _ = nn.utils.rnn.pad_packed_sequence(x)\n","        x = self.drop(x)\n","        # x, _ = self.lstm2(x)\n","        # x, _ = self.lstm3(x)\n","        if self.uselast:\n","            x = x[:,-1].view(len(x), -1)\n","        elif self.maxpool:\n","            x = torch.transpose(x, 1, 2)#torch.Size([batch, hidden, seq])\n","            x = torch.tanh(x)\n","            x, indices = F.max_pool1d(x,x.size(2), return_indices=True)\n","            x = torch.tanh(x)\n","            x = x.squeeze(2)\n","        else:\n","            x = torch.mean(x, dim=1)\n","        # x = self.relu(self.dense(x))\n","        # x = self.drop(x)\n","        x = self.out(x)\n","        x = self.softmax(x)\n","        return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vRwRqK-Amxjc","colab_type":"code","colab":{}},"source":["num_categories = len(categories)\n","batch_size=128 \n","n_lr = 5e-3\n","decay = 1e-7\n","n_epochs = 10\n","lstm_out = [128,64,32]\n","dense_layer = 64\n","SEED = 10\n","n_splits = 9"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zarF-n6nsGMq","colab_type":"code","outputId":"9d6fa179-05a9-4ca2-f875-d6b829d34cf4","executionInfo":{"status":"ok","timestamp":1574538777148,"user_tz":-120,"elapsed":594,"user":{"displayName":"Mina 3.Melek","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAWTZeaXL6pBID15v903jVhJLIYLmIkX1FgP2jL=s64","userId":"10444321559887690581"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["beg = time.time()\n","model = LSTMTopic(weights_matrix, lstm_out, dense_layer, num_categories,True,False)\n","model.load_state_dict(torch.load(os.path.join(curDir,'ModelData','Pytorch_Model','model_state_dict_v3_1.pth')))\n","print(\"Loading time = %.2fs\"%(time.time()-beg))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Loading time = 0.24s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3wCHpHwCbK-z","colab_type":"code","outputId":"bb982c03-c6ae-4397-b7f8-0787d409f516","executionInfo":{"status":"ok","timestamp":1574538801462,"user_tz":-120,"elapsed":17652,"user":{"displayName":"Mina 3.Melek","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAWTZeaXL6pBID15v903jVhJLIYLmIkX1FgP2jL=s64","userId":"10444321559887690581"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["CPU = True\n","if CPU:\n","    # device = torch.device(\"cpu\")\n","    model.cpu()\n","    x_tt = torch.tensor(x_train, dtype=torch.long)\n","    y_tt = torch.tensor(y_train, dtype=torch.float32)\n","    y_pp = model(x_tt)\n","    x_t = torch.tensor(x_test, dtype=torch.long)\n","    y_t = torch.tensor(y_test, dtype=torch.float32)\n","    beg = time.time()\n","    y_p = model(x_t)\n","else:\n","    model.cuda()\n","    x_tt = torch.tensor(x_train, dtype=torch.long).cuda()\n","    y_tt = torch.tensor(y_train, dtype=torch.float32).cuda()\n","    y_pp = model(x_tt).detach()\n","    x_t = torch.tensor(x_test, dtype=torch.long).cuda()\n","    y_t = torch.tensor(y_test, dtype=torch.float32).cuda()\n","    beg = time.time()\n","    y_p = model(x_t).detach()\n","    \n","print('Predicted Train accuracy ',(y_pp.argmax(dim=1)==y_tt.argmax(dim=1)).sum().cpu().numpy()/len(y_pp))\n","print('Predicted Test accuracy ',(y_p.argmax(dim=1)==y_t.argmax(dim=1)).sum().cpu().numpy()/len(y_p))\n","print(\"prediction time = %.2fs\"%(time.time()-beg))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Predicted Train accuracy  0.7165332769071832\n","Predicted Test accuracy  0.567349580543178\n","prediction time = 2.75s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9nMEs2zexdn0","colab_type":"code","outputId":"ae838549-30cd-4759-e0fb-46fd10b34474","executionInfo":{"status":"ok","timestamp":1574538816328,"user_tz":-120,"elapsed":3671,"user":{"displayName":"Mina 3.Melek","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAWTZeaXL6pBID15v903jVhJLIYLmIkX1FgP2jL=s64","userId":"10444321559887690581"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["beg = time.time()\n","y_p = model(x_t)\n","print('Predicted Test accuracy ',(y_p.argmax(dim=1)==y_t.argmax(dim=1)).sum().cpu().numpy()/len(y_p))\n","print(\"prediction time = %.2fs\"%(time.time()-beg))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Predicted Test accuracy  0.5686938338602474\n","prediction time = 3.04s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"A8LN4-8N2mA6","colab_type":"code","outputId":"54831f88-5e51-4dda-9c50-4ebb9c67952e","executionInfo":{"status":"ok","timestamp":1574538818105,"user_tz":-120,"elapsed":617,"user":{"displayName":"Mina 3.Melek","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAWTZeaXL6pBID15v903jVhJLIYLmIkX1FgP2jL=s64","userId":"10444321559887690581"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["f1_score(y_t.argmax(dim=1).cpu(), y_p.argmax(dim=1).cpu(),list(int_category.values()),average='weighted')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n","  'precision', 'predicted', average, warn_for)\n","/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n","  'recall', 'true', average, warn_for)\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"W-M0jHrKpxWJ","colab_type":"code","outputId":"700fb353-698d-48cc-d020-9e4f9404369f","executionInfo":{"status":"ok","timestamp":1574538831826,"user_tz":-120,"elapsed":1289,"user":{"displayName":"Mina 3.Melek","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAWTZeaXL6pBID15v903jVhJLIYLmIkX1FgP2jL=s64","userId":"10444321559887690581"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["print('Train statistics:')\n","print('accuracy %s' % accuracy_score(y_pp.argmax(dim=1).cpu(), y_tt.argmax(dim=1).cpu()))\n","print(classification_report(y_tt.argmax(dim=1).cpu(), y_pp.argmax(dim=1).cpu(),target_names=list(int_category.values())))\n","print('Test statistics:')\n","print('accuracy %s' % accuracy_score(y_p.argmax(dim=1).cpu(), y_t.argmax(dim=1).cpu()))\n","print(classification_report(y_t.argmax(dim=1).cpu(), y_p.argmax(dim=1).cpu(),target_names=list(int_category.values())))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train statistics:\n","accuracy 0.7165332769071832\n","                precision    recall  f1-score   support\n","\n","          ARTS       0.52      0.39      0.44      1245\n","ARTS & CULTURE       0.49      0.42      0.45      1086\n","  BLACK VOICES       0.68      0.63      0.66      3664\n","      BUSINESS       0.67      0.63      0.65      4763\n","       COLLEGE       0.64      0.53      0.58       915\n","        COMEDY       0.70      0.57      0.63      4086\n","         CRIME       0.73      0.74      0.74      2708\n","CULTURE & ARTS       0.67      0.50      0.57       867\n","       DIVORCE       0.79      0.76      0.78      2717\n","     EDUCATION       0.53      0.39      0.45       806\n"," ENTERTAINMENT       0.78      0.83      0.81     12818\n","   ENVIRONMENT       0.66      0.48      0.56      1068\n","         FIFTY       0.48      0.30      0.37      1125\n","  FOOD & DRINK       0.75      0.84      0.79      4998\n","     GOOD NEWS       0.52      0.45      0.48      1134\n","         GREEN       0.56      0.54      0.55      2082\n","HEALTHY LIVING       0.52      0.36      0.42      5287\n"," HOME & LIVING       0.84      0.85      0.85      3355\n","        IMPACT       0.53      0.37      0.43      2747\n"," LATINO VOICES       0.76      0.53      0.62       902\n","         MEDIA       0.74      0.61      0.67      2245\n","         MONEY       0.66      0.55      0.60      1390\n","     PARENTING       0.59      0.69      0.64      6944\n","       PARENTS       0.52      0.39      0.44      3158\n","      POLITICS       0.81      0.88      0.84     26268\n","  QUEER VOICES       0.77      0.75      0.76      5026\n","      RELIGION       0.70      0.66      0.68      2036\n","       SCIENCE       0.68      0.67      0.68      1727\n","        SPORTS       0.83      0.84      0.84      3863\n","         STYLE       0.63      0.53      0.57      1797\n","STYLE & BEAUTY       0.84      0.87      0.85      7754\n","         TASTE       0.63      0.44      0.52      1649\n","          TECH       0.66      0.69      0.68      1649\n","        TRAVEL       0.82      0.87      0.85      7952\n","      WEDDINGS       0.84      0.83      0.84      2895\n","    WEIRD NEWS       0.61      0.54      0.57      2129\n","      WELLNESS       0.63      0.80      0.70     14231\n","         WOMEN       0.52      0.44      0.48      2815\n","    WORLD NEWS       0.61      0.33      0.42      1749\n","     WORLDPOST       0.66      0.74      0.69      5032\n","\n","      accuracy                           0.72    160682\n","     macro avg       0.66      0.61      0.63    160682\n","  weighted avg       0.71      0.72      0.71    160682\n","\n","Test statistics:\n","accuracy 0.5686938338602474\n","                precision    recall  f1-score   support\n","\n","          ARTS       0.25      0.19      0.22       264\n","ARTS & CULTURE       0.26      0.23      0.24       253\n","  BLACK VOICES       0.39      0.37      0.38       864\n","      BUSINESS       0.43      0.42      0.42      1174\n","       COLLEGE       0.44      0.36      0.40       229\n","        COMEDY       0.51      0.37      0.43      1089\n","         CRIME       0.52      0.54      0.53       697\n","CULTURE & ARTS       0.34      0.28      0.30       163\n","       DIVORCE       0.69      0.61      0.65       709\n","     EDUCATION       0.33      0.26      0.29       198\n"," ENTERTAINMENT       0.62      0.67      0.64      3240\n","   ENVIRONMENT       0.39      0.27      0.32       255\n","         FIFTY       0.27      0.15      0.19       276\n","  FOOD & DRINK       0.61      0.71      0.66      1228\n","     GOOD NEWS       0.27      0.28      0.28       264\n","         GREEN       0.40      0.35      0.37       540\n","HEALTHY LIVING       0.33      0.21      0.26      1407\n"," HOME & LIVING       0.71      0.70      0.70       840\n","        IMPACT       0.35      0.22      0.27       712\n"," LATINO VOICES       0.45      0.29      0.35       227\n","         MEDIA       0.55      0.42      0.47       570\n","         MONEY       0.42      0.33      0.37       317\n","     PARENTING       0.47      0.56      0.51      1733\n","       PARENTS       0.40      0.28      0.33       797\n","      POLITICS       0.72      0.80      0.76      6471\n","  QUEER VOICES       0.67      0.62      0.64      1288\n","      RELIGION       0.53      0.49      0.51       520\n","       SCIENCE       0.48      0.45      0.46       451\n","        SPORTS       0.67      0.64      0.65      1021\n","         STYLE       0.35      0.26      0.30       457\n","STYLE & BEAUTY       0.72      0.75      0.73      1895\n","         TASTE       0.34      0.20      0.25       447\n","          TECH       0.46      0.49      0.47       433\n","        TRAVEL       0.66      0.74      0.70      1935\n","      WEDDINGS       0.72      0.71      0.72       756\n","    WEIRD NEWS       0.32      0.28      0.30       541\n","      WELLNESS       0.52      0.68      0.59      3596\n","         WOMEN       0.35      0.32      0.34       675\n","    WORLD NEWS       0.33      0.15      0.21       428\n","     WORLDPOST       0.51      0.58      0.55      1211\n","\n","      accuracy                           0.57     40171\n","     macro avg       0.47      0.43      0.44     40171\n","  weighted avg       0.55      0.57      0.56     40171\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ohLnzOpc6w9V","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}