{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Train-glove.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Rp3kU3j9TQmk","colab_type":"code","colab":{}},"source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import sys\n","import os\n","import time\n","import copy\n","import pickle\n","import random\n","from random import shuffle \n","import matplotlib.pyplot as plt\n","from scipy import spatial\n","\n","from sklearn.manifold import TSNE\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, classification_report\n","# from keras.utils.np_utils import to_categorical\n","from gensim.models import Word2Vec\n","from multiprocessing import cpu_count\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n","from torch.autograd import Variable\n","# from torchtext.data import Example\n","# import torchtext\n","\n","torch.manual_seed(10)\n","\n","\n","%load_ext autoreload\n","%autoreload 2\n","this = sys.modules[__name__]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"03wgE_DeTv_p","colab_type":"code","outputId":"1f5fa128-b67a-49e6-9ebb-cae34951c789","executionInfo":{"status":"ok","timestamp":1574543150056,"user_tz":-120,"elapsed":44804,"user":{"displayName":"Mina 3.Melek","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAWTZeaXL6pBID15v903jVhJLIYLmIkX1FgP2jL=s64","userId":"10444321559887690581"}},"colab":{"base_uri":"https://localhost:8080/","height":182}},"source":["import nltk\n","nltk.download('wordnet')\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","# from model import lstm\n","# os.chdir(curDir+'/data')\n","import reader # reader.py"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"cOfOFTBNSu1U","colab_type":"code","colab":{}},"source":["def read_preTrained(file_name):\n","    with open(file_name,'r') as f:\n","        word_vocab = set() # not using list to avoid duplicate entry\n","        word2vector = {}\n","        for line in f:\n","            line_ = line.strip() #Remove white space\n","            words_Vec = line_.split()\n","            if len(words_Vec) > 301:\n","                continue\n","            try:\n","                word_vocab.add(words_Vec[0])\n","                word2vector[words_Vec[0]] = np.array(words_Vec[1:],dtype=float)\n","            except ValueError:\n","                continue\n","    return word_vocab,word2vector\n","\n","def read_numpy_files():\n","    \"\"\"Instead of running the entire pipeline at all times.\"\"\"\n","    filename = os.path.join(curDir, 'data', 'train_test_data.dat') ##@\n","    with open(filename, 'rb') as handle:\n","        x_train = pickle.load(handle)\n","        y_train = pickle.load(handle)\n","        x_test = pickle.load(handle)\n","        y_test = pickle.load(handle)\n","        int_category = pickle.load(handle)\n","        category_int = pickle.load(handle)\n","\n","    return (x_train, y_train), (x_test, y_test), int_category, category_int\n","\n","def seed_everything(seed=10):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xdlj0K02MVhO","colab_type":"code","outputId":"089575cb-e9c7-41a6-da21-bfdf93759b29","executionInfo":{"status":"ok","timestamp":1574543151432,"user_tz":-120,"elapsed":46144,"user":{"displayName":"Mina 3.Melek","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAWTZeaXL6pBID15v903jVhJLIYLmIkX1FgP2jL=s64","userId":"10444321559887690581"}},"colab":{"base_uri":"https://localhost:8080/","height":221}},"source":["document_max_num_words = 15\n","emb_dim = 300\n","firstTime = False\n","cache = True\n","reuters = False\n","reader.generate_categories(reuters)\n","class_names = reader.categories \n","print('reading data...')\n","print('# of dimensions is: ', emb_dim)\n","(x_train, y_train), (x_test, y_test), int_category, category_int = read_numpy_files()\n","# vocabulary = np.insert(np.load('./data/vocabulary.npy'), 0, '')\n","vocabulary = np.load('./data/vocabulary.npy')\n","categories = np.load('./data/categories.npy')\n","print('Training data size: ', x_train.shape, y_train.shape)\n","print('Testing data size: ', x_test.shape, y_test.shape)\n","print('Vocabulary size: ', len(vocabulary))\n","print('Categories: ', len(categories), categories)\n","# print(int_category)\n","# word_to_ix = {word: i for i, word in enumerate(vocabulary)}\n","# bad_score = ['COLLEGE', 'ENVIRONMENT', 'FIFTY', 'HEALTHY LIVING', 'LATINO VOICES', 'MONEY', 'PARENTS', 'TASTE', 'WORLD NEWS']\n","# x_train = reader.vectorize_idx(x_train, word_to_ix, document_max_num_words)\n","# y_train = np.array(list(y_train.values()))\n","# x_test = reader.vectorize_idx(x_test, word_to_ix, document_max_num_words)\n","# y_test = np.array(list(y_test.values()))\n","# reader.save_data(x_train, y_train, x_test, y_test, int_category, category_int)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["reading data...\n","# of dimensions is:  300\n","Training data size:  (160682, 15) (160682, 40)\n","Testing data size:  (40171, 15) (40171, 40)\n","Vocabulary size:  55618\n","Categories:  40 ['ARTS' 'ARTS & CULTURE' 'BLACK VOICES' 'BUSINESS' 'COLLEGE' 'COMEDY'\n"," 'CRIME' 'CULTURE & ARTS' 'DIVORCE' 'EDUCATION' 'ENTERTAINMENT'\n"," 'ENVIRONMENT' 'FIFTY' 'FOOD & DRINK' 'GOOD NEWS' 'GREEN' 'HEALTHY LIVING'\n"," 'HOME & LIVING' 'IMPACT' 'LATINO VOICES' 'MEDIA' 'MONEY' 'PARENTING'\n"," 'PARENTS' 'POLITICS' 'QUEER VOICES' 'RELIGION' 'SCIENCE' 'SPORTS' 'STYLE'\n"," 'STYLE & BEAUTY' 'TASTE' 'TECH' 'TRAVEL' 'WEDDINGS' 'WEIRD NEWS'\n"," 'WELLNESS' 'WOMEN' 'WORLD NEWS' 'WORLDPOST']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"F635A78QzyDR","colab_type":"code","outputId":"0691fc8e-41d1-4f15-fefd-7d59d1d9c539","executionInfo":{"status":"ok","timestamp":1574543154597,"user_tz":-120,"elapsed":49284,"user":{"displayName":"Mina 3.Melek","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAWTZeaXL6pBID15v903jVhJLIYLmIkX1FgP2jL=s64","userId":"10444321559887690581"}},"colab":{"base_uri":"https://localhost:8080/","height":173}},"source":["y = np.concatenate((y_train, y_test))\n","unique, counts = np.unique(y, return_counts=True,axis=0)\n","print(dict(zip(unique.argmax(1), counts)))\n","states = counts[::-1]/len(y)\n","# pos_weight=np.copy(states)\n","# pos_weight[np.where(pos_weight<0.01)]=5\n","# pos_weight[np.where(pos_weight<0.02)]=2\n","# pos_weight[np.where(pos_weight<0.05)]=1\n","# pos_weight[np.where(pos_weight<0.16)]=0.5\n","# pos_weight[np.where(states>=0.16)]=0.25\n","pos_weight=states.min()/states*5\n","print(pos_weight)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["{39: 6243, 38: 2177, 37: 3490, 36: 17827, 35: 2670, 34: 3651, 33: 9887, 32: 2082, 31: 2096, 30: 9649, 29: 2254, 28: 4884, 27: 2178, 26: 2556, 25: 6314, 24: 32739, 23: 3955, 22: 8677, 21: 1707, 20: 2815, 19: 1129, 18: 3459, 17: 4195, 16: 6694, 15: 2622, 14: 1398, 13: 6226, 12: 1401, 11: 1323, 10: 16058, 9: 1004, 8: 3426, 7: 1030, 6: 3405, 5: 5175, 4: 1144, 3: 5937, 2: 4528, 1: 1339, 0: 1509}\n","[3.32670643 3.74906647 1.10865724 0.84554489 4.38811189 0.97004831\n"," 1.4743025  4.87378641 1.46526562 5.         0.31261676 3.79440665\n"," 3.58315489 0.80629618 3.59084406 1.91456903 0.74992531 1.19666269\n"," 1.4512865  4.44641275 1.78330373 2.94083187 0.57854097 1.26927939\n"," 0.15333394 0.7950586  1.96400626 2.30486685 1.02784603 2.22715173\n"," 0.52026117 2.39503817 2.41114313 0.50773743 1.37496576 1.88014981\n"," 0.28159533 1.43839542 2.30592559 0.80410059]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"E5vaklRFXriJ","outputId":"1e7c76c2-efdc-4f15-fd3d-71c8c2d8f176","executionInfo":{"status":"ok","timestamp":1574543157202,"user_tz":-120,"elapsed":51870,"user":{"displayName":"Mina 3.Melek","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAWTZeaXL6pBID15v903jVhJLIYLmIkX1FgP2jL=s64","userId":"10444321559887690581"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# vocab, w2v = read_preTrained(\"./model/glove_files/glove.840B.300d.txt\")\n","# print(\"Total Words in DataSet:\",len(vocab))\n","# emb_dim = w2v[list(vocab)[0]].shape[0]\n","# matrix_len = len(vocabulary)\n","# weights_matrix = np.zeros((matrix_len, emb_dim))\n","# words_not_found = 0\n","# n_words = []\n","\n","# for i, word in enumerate(vocabulary):\n","#     try: \n","#         weights_matrix[i] = w2v[word]\n","#     except KeyError:\n","#         weights_matrix[i] = np.random.normal(scale=0.6, size=(emb_dim, ))\n","#         words_not_found += 1\n","#         n_words.append(word)\n","\n","# print('words not found:', words_not_found)\n","# print('random embedded words percentage = %.2f%%'%(words_not_found/(matrix_len)*100))\n","# import gc\n","# w2v.clear() \n","# del w2v, vocab\n","# gc.collect()\n","# len(n_words)\n","# n_words[:50]\n","# np.savez_compressed('./data/weights_matrix_840B', weights_matrix)\n","weights_matrix = np.load('./data/weights_matrix_840B.npz')['arr_0']\n","weights_matrix = torch.tensor(weights_matrix, dtype=torch.float64)\n","print(weights_matrix.size())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["torch.Size([55618, 300])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"L9KPoy7bOp-L","colab_type":"code","colab":{}},"source":["class MyDataset(Dataset):\n","    def __init__(self,dataset):\n","        self.dataset = dataset\n","    def __getitem__(self,index):\n","        data,target = self.dataset[index]\n","        return data,target,index\n","    def __len__(self):\n","        return len(self.dataset)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qSINXT7dQfKz","colab_type":"code","colab":{}},"source":["class LSTMTopic(nn.Module):\n","\n","    def __init__(self, weights_matrix, lstm_out, dense_out, num_categories, noEmbTrain=True, uselast=True, maxpool=False):\n","        super(LSTMTopic, self).__init__()\n","        self.hidden_dim = lstm_out[1]\n","        self.uselast = uselast\n","        self.maxpool = maxpool\n","        num_embeddings, embedding_dim = weights_matrix.size()\n","        self.embedding = nn.Embedding.from_pretrained(weights_matrix, freeze=noEmbTrain)\n","        #self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n","\n","        # The LSTM takes word embeddings as inputs, and outputs hidden states\n","        # with dimensionality hidden_dim.\n","        self.lstm1 = nn.LSTM(embedding_dim, self.hidden_dim , 2, batch_first=True, dropout=0.5)\n","        self.lstm2 = nn.LSTM(embedding_dim, self.hidden_dim , 1, batch_first=True)\n","        # The linear layer that maps from hidden state space to tag space\n","        # self.dense= nn.Linear(self.hidden_dim , dense_out)\n","        # self.relu = nn.ReLU()\n","        self.drop = nn.Dropout(0.5)\n","        self.out = nn.Linear(self.hidden_dim , num_categories)\n","        self.softmax = nn.Softmax(dim=1)\n","\n","    def forward(self, inputs):\n","        x = self.embedding(inputs)\n","        x, (h, c) = self.lstm1(x.float())\n","        #x, _ = nn.utils.rnn.pad_packed_sequence(x)\n","        x = self.drop(x)\n","        # x, _ = self.lstm2(x)\n","        # x, _ = self.lstm3(x)\n","        if self.uselast:\n","            x = x[:,-1].view(len(x), -1)\n","        elif self.maxpool:\n","            x = torch.transpose(x, 1, 2)#torch.Size([batch, hidden, seq])\n","            x = torch.tanh(x)\n","            x, indices = F.max_pool1d(x,x.size(2), return_indices=True)\n","            x = torch.tanh(x)\n","            x = x.squeeze(2)\n","        else:\n","            x = torch.mean(x, dim=1)\n","        # x = self.relu(self.dense(x))\n","        # x = self.drop(x)\n","        x = self.out(x)\n","        x = self.softmax(x)\n","        return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vRwRqK-Amxjc","colab_type":"code","colab":{}},"source":["num_categories = len(categories)\n","batch_size=128 \n","n_lr = 5e-3\n","decay = 1e-7\n","n_epochs = 20\n","lstm_out = [128,64,32]\n","dense_layer = 64\n","SEED = 10\n","n_splits = 9"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"67m8NOkHnvvk","colab_type":"code","colab":{}},"source":["def pytorch_model_run_cv(x_train,y_train,features,x_test, y_test, model_obj, Cats, pos_weight, feats = False,clip = True):\n","    seed_everything()\n","    avg_losses_f = []\n","    avg_val_losses_f = []\n","    avg_accs_f = []\n","    avg_val_accs_f = []\n","    pos_weight = torch.tensor(pos_weight, dtype=torch.float32).cuda()\n","    # matrix for the out-of-fold predictions\n","    train_preds = np.zeros((len(x_train),Cats))\n","    # matrix for the predictions on the test set\n","    test_preds = np.zeros((len(x_test), Cats))\n","    splits = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED).split(x_train, y_train[:,1])\n","    x_test = torch.tensor(x_test, dtype=torch.long).cuda()\n","    y_test = torch.tensor(y_test, dtype=torch.float32).cuda()\n","    test = MyDataset(torch.utils.data.TensorDataset(x_test, y_test))\n","    test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)\n","    for i, (train_idx, valid_idx) in enumerate(splits):\n","        seed_everything(i*1000+i)\n","        x_train = np.array(x_train)\n","        y_train = np.array(y_train)\n","        if feats:\n","            features = np.array(features)\n","        x_train_fold = torch.tensor(x_train[train_idx.astype(int)], dtype=torch.long).cuda()\n","        y_train_fold = torch.tensor(y_train[train_idx.astype(int), np.newaxis], dtype=torch.float32).cuda()\n","        if feats:\n","            kfold_X_features = features[train_idx.astype(int)]\n","            kfold_X_valid_features = features[valid_idx.astype(int)]\n","        x_val_fold = torch.tensor(x_train[valid_idx.astype(int)], dtype=torch.long).cuda()\n","        y_val_fold = torch.tensor(y_train[valid_idx.astype(int), np.newaxis], dtype=torch.float32).cuda()\n","\n","        model = copy.deepcopy(model_obj)\n","\n","        model.cuda()\n","\n","        loss_fn = nn.BCELoss()#(pos_weight=pos_weight)#(reduction='sum')\n","\n","        step_size = 300\n","        base_lr, max_lr = n_lr/5, n_lr   \n","        optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), \n","                                 lr=max_lr)\n","\n","        ################################################################################################\n","        scheduler = optim.lr_scheduler.CyclicLR(optimizer, base_lr=base_lr, max_lr=max_lr,\n","                   step_size_up=step_size, mode='exp_range',\n","                   gamma=0.99994, cycle_momentum=False)\n","        ###############################################################################################\n","        #print('xtrain',X_train[0])\n","        #print('xtrainF',x_train_fold[0])\n","\n","        train = MyDataset(torch.utils.data.TensorDataset(x_train_fold, y_train_fold))\n","        #print('train',train[0])\n","        valid = MyDataset(torch.utils.data.TensorDataset(x_val_fold, y_val_fold))\n","\n","        train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n","        #print('loader',train_loader[0])\n","        valid_loader = torch.utils.data.DataLoader(valid, batch_size=batch_size, shuffle=False)\n","\n","        print(f'Fold {i + 1}')\n","        for epoch in range(n_epochs):\n","            start_time = time.time()\n","            model.train()\n","\n","            avg_loss = 0.  \n","            avg_acc = 0.\n","            for i, (x_batch, y_batch, index) in enumerate(train_loader):\n","                y_batch = y_batch.view(len(y_batch), -1)\n","                if feats:       \n","                    f = kfold_X_features[index]\n","                    y_pred = model([x_batch,f])\n","                else:\n","                    y_pred = model(x_batch)\n","\n","                \n","                # Compute and print loss.\n","                #print(y_pred.shape, y_batch.shape)\n","                loss = loss_fn(y_pred, y_batch)\n","                optimizer.zero_grad()\n","                loss.backward()\n","                if clip:\n","                    nn.utils.clip_grad_norm_(model.parameters(),1)\n","                optimizer.step()\n","                if scheduler:\n","                    scheduler.step()\n","\n","                avg_loss += loss.item() / len(train_loader)\n","                acc =(y_pred.argmax(dim=1)==y_batch.argmax(dim=1)).sum().cpu().numpy()/len(y_pred)\n","                avg_acc += acc / len(train_loader)\n","            #avg_loss /= i+1\n","            #avg_acc /= i+1\n","                \n","\n","            model.eval()\n","\n","            valid_preds_fold = np.zeros((x_val_fold.size(0), Cats))\n","            test_preds_fold = np.zeros((len(x_test), Cats))\n","\n","            avg_val_loss = 0.\n","            avg_val_acc = 0.\n","            for i, (x_batch, y_batch, index) in enumerate(valid_loader):\n","                y_batch = y_batch.view(len(y_batch), -1)\n","                if feats:\n","                    f = kfold_X_valid_features[index]            \n","                    y_pred = model([x_batch,f]).detach()\n","                else:\n","                    y_pred = model(x_batch).detach()\n","\n","                avg_val_loss += loss_fn(y_pred, y_batch).item() / len(valid_loader)\n","                val_acc =(y_pred.argmax(dim=1)==y_batch.argmax(dim=1)).sum().cpu().numpy()/len(y_pred)\n","                avg_val_acc += val_acc / len(valid_loader)\n","                valid_preds_fold[index] = y_pred.cpu().numpy()#[:, 0]\n","            #avg_val_loss /= i+1\n","            #avg_val_acc /= i+1\n","\n","            elapsed_time = time.time() - start_time \n","            print('Epoch {}/{} \\t loss={:.4f} \\t acc={:.4f} \\t val_loss={:.4f} \\t avg_val_acc={:.4f} \\t time={:.2f}s'.format(\n","                epoch + 1, n_epochs, avg_loss, avg_acc, avg_val_loss, avg_val_acc, elapsed_time))\n","            avg_losses_f.append(avg_loss)\n","            avg_val_losses_f.append(avg_val_loss) \n","            avg_accs_f.append(avg_acc)\n","            avg_val_accs_f.append(avg_val_acc) \n","        \n","        # predict all samples in the test set batch per batch\n","        for i, (x_batch, y_batch, index) in enumerate(test_loader):\n","            if feats:\n","                f = test_features[i * batch_size:(i+1) * batch_size]\n","                y_pred = model([x_batch,f]).detach()\n","            else:\n","                y_pred = model(x_batch).detach()\n","\n","            test_preds_fold[i * batch_size:(i+1) * batch_size] = y_pred.cpu().numpy()#[:, 0]\n","\n","        train_preds[valid_idx] = valid_preds_fold\n","        test_preds += test_preds_fold / n_splits\n","        break\n","    print('All \\t loss={:.4f} \\t acc={:.4f} \\t val_loss={:.4f} \\t avg_val_acc={:.4f} \\t '\n","          .format(np.average(avg_losses_f),np.average(avg_accs_f),np.average(avg_val_losses_f),np.average(avg_val_accs_f)))\n","    return model, train_preds, test_preds, avg_losses_f, avg_val_losses_f"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zarF-n6nsGMq","colab_type":"code","outputId":"3b6f1b27-3e23-4ec0-84a6-4511f665a850","executionInfo":{"status":"ok","timestamp":1574543579268,"user_tz":-120,"elapsed":194627,"user":{"displayName":"Mina 3.Melek","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAWTZeaXL6pBID15v903jVhJLIYLmIkX1FgP2jL=s64","userId":"10444321559887690581"}},"colab":{"base_uri":"https://localhost:8080/","height":408}},"source":["beg = time.time()\n","model_obj = LSTMTopic(weights_matrix, lstm_out, dense_layer, num_categories,True,False)\n","# model_obj.load_state_dict(torch.load(os.path.join(curDir,'ModelData','Pytorch_Model','model_state_dict_v3.pth')))\n","model, train_preds, test_preds, avg_losses_f, avg_val_losses_f = pytorch_model_run_cv(x_train,y_train,0,x_test,y_test, model_obj, num_categories, pos_weight, feats = False,clip = True)\n","print(\"Training time = %.2fs\"%(time.time()-beg))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Fold 1\n","Epoch 1/20 \t loss=0.0685 \t acc=0.4782 \t val_loss=0.0576 \t avg_val_acc=0.5524 \t time=9.60s\n","Epoch 2/20 \t loss=0.0562 \t acc=0.5687 \t val_loss=0.0556 \t avg_val_acc=0.5687 \t time=9.51s\n","Epoch 3/20 \t loss=0.0531 \t acc=0.5899 \t val_loss=0.0546 \t avg_val_acc=0.5760 \t time=9.56s\n","Epoch 4/20 \t loss=0.0512 \t acc=0.6049 \t val_loss=0.0541 \t avg_val_acc=0.5862 \t time=9.70s\n","Epoch 5/20 \t loss=0.0498 \t acc=0.6158 \t val_loss=0.0537 \t avg_val_acc=0.5895 \t time=9.31s\n","Epoch 6/20 \t loss=0.0487 \t acc=0.6239 \t val_loss=0.0543 \t avg_val_acc=0.5929 \t time=10.15s\n","Epoch 7/20 \t loss=0.0476 \t acc=0.6339 \t val_loss=0.0544 \t avg_val_acc=0.5930 \t time=9.36s\n","Epoch 8/20 \t loss=0.0465 \t acc=0.6403 \t val_loss=0.0544 \t avg_val_acc=0.5929 \t time=9.93s\n","Epoch 9/20 \t loss=0.0456 \t acc=0.6487 \t val_loss=0.0556 \t avg_val_acc=0.5876 \t time=9.54s\n","Epoch 10/20 \t loss=0.0449 \t acc=0.6534 \t val_loss=0.0564 \t avg_val_acc=0.5872 \t time=9.86s\n","Epoch 11/20 \t loss=0.0442 \t acc=0.6597 \t val_loss=0.0569 \t avg_val_acc=0.5849 \t time=9.63s\n","Epoch 12/20 \t loss=0.0435 \t acc=0.6642 \t val_loss=0.0569 \t avg_val_acc=0.5885 \t time=9.42s\n","Epoch 13/20 \t loss=0.0430 \t acc=0.6677 \t val_loss=0.0581 \t avg_val_acc=0.5883 \t time=9.60s\n","Epoch 14/20 \t loss=0.0424 \t acc=0.6723 \t val_loss=0.0582 \t avg_val_acc=0.5882 \t time=9.74s\n","Epoch 15/20 \t loss=0.0418 \t acc=0.6782 \t val_loss=0.0594 \t avg_val_acc=0.5876 \t time=9.44s\n","Epoch 16/20 \t loss=0.0412 \t acc=0.6832 \t val_loss=0.0598 \t avg_val_acc=0.5825 \t time=9.65s\n","Epoch 17/20 \t loss=0.0407 \t acc=0.6871 \t val_loss=0.0608 \t avg_val_acc=0.5810 \t time=9.73s\n","Epoch 18/20 \t loss=0.0403 \t acc=0.6901 \t val_loss=0.0610 \t avg_val_acc=0.5819 \t time=9.95s\n","Epoch 19/20 \t loss=0.0398 \t acc=0.6933 \t val_loss=0.0617 \t avg_val_acc=0.5822 \t time=9.44s\n","Epoch 20/20 \t loss=0.0395 \t acc=0.6939 \t val_loss=0.0619 \t avg_val_acc=0.5809 \t time=9.88s\n","All \t loss=0.0464 \t acc=0.6424 \t val_loss=0.0573 \t avg_val_acc=0.5836 \t \n","Training time = 193.97s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"nzDKId4rJ2UQ","outputId":"c52e87fe-323a-45dd-8259-0b3a62f8bee1","executionInfo":{"status":"ok","timestamp":1574543579271,"user_tz":-120,"elapsed":188381,"user":{"displayName":"Mina 3.Melek","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAWTZeaXL6pBID15v903jVhJLIYLmIkX1FgP2jL=s64","userId":"10444321559887690581"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["print('Average Train accuracy ',(train_preds.argmax(1)==y_train.argmax(1)).sum()/len(y_train))\n","print('Average Test accuracy ',(test_preds.argmax(1)==y_test.argmax(1)).sum()/len(y_test))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Average Train accuracy  0.07145791065582953\n","Average Test accuracy  0.5827338129496403\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VNj5Ud0gsgiC","colab_type":"code","outputId":"04e7a69f-53cf-4110-c8c4-60d05f81f65e","executionInfo":{"status":"ok","timestamp":1574543579602,"user_tz":-120,"elapsed":188414,"user":{"displayName":"Mina 3.Melek","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAWTZeaXL6pBID15v903jVhJLIYLmIkX1FgP2jL=s64","userId":"10444321559887690581"}},"colab":{"base_uri":"https://localhost:8080/","height":265}},"source":["t = np.arange(len(avg_losses_f))\n","plt.figure()\n","\n","plt.plot(t, avg_losses_f, 'b', t, avg_val_losses_f, 'r')\n","plt.show()"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"3wCHpHwCbK-z","colab_type":"code","outputId":"8c6c0942-96de-42dd-a838-06926505e368","executionInfo":{"status":"ok","timestamp":1574543741887,"user_tz":-120,"elapsed":677,"user":{"displayName":"Mina 3.Melek","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAWTZeaXL6pBID15v903jVhJLIYLmIkX1FgP2jL=s64","userId":"10444321559887690581"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["CPU = True\n","s = x_test.shape[0]\n","if CPU:\n","    # device = torch.device(\"cpu\")\n","    model.cpu()\n","    x_tt = torch.tensor(x_train[:s], dtype=torch.long)\n","    y_tt = torch.tensor(y_train[:s], dtype=torch.float32)\n","    y_pp = model(x_tt)\n","    x_t = torch.tensor(x_test, dtype=torch.long)\n","    y_t = torch.tensor(y_test, dtype=torch.float32)\n","    y_p = model(x_t)\n","else:\n","    x_tt = torch.tensor(x_train, dtype=torch.long).cuda()\n","    y_tt = torch.tensor(y_train, dtype=torch.float32).cuda()\n","    y_pp = model(x_tt).detach()\n","    x_t = torch.tensor(x_test, dtype=torch.long).cuda()\n","    y_t = torch.tensor(y_test, dtype=torch.float32).cuda()\n","    y_p = model(x_t).detach()\n","    \n","print('Predicted Train accuracy ',(y_pp.argmax(dim=1)==y_tt.argmax(dim=1)).sum().cpu().numpy()/len(y_pp))\n","print('Predicted Test accuracy ',(y_p.argmax(dim=1)==y_t.argmax(dim=1)).sum().cpu().numpy()/len(y_p))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Predicted Train accuracy  0.7199223320305693\n","Predicted Test accuracy  0.5827338129496403\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"A8LN4-8N2mA6","colab_type":"code","outputId":"c13f06e6-c6fc-4a16-f19e-830f5ccc4fdc","executionInfo":{"status":"ok","timestamp":1573133752153,"user_tz":-120,"elapsed":770,"user":{"displayName":"My Eye","photoUrl":"","userId":"01160329479424385690"}},"colab":{"base_uri":"https://localhost:8080/","height":108}},"source":["f1_score(y_t.argmax(dim=1).cpu(), y_p.argmax(dim=1).cpu(),list(int_category.values()),average='weighted')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n","  'precision', 'predicted', average, warn_for)\n","/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n","  'recall', 'true', average, warn_for)\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{"tags":[]},"execution_count":85}]},{"cell_type":"code","metadata":{"id":"W-M0jHrKpxWJ","colab_type":"code","outputId":"39affd20-c6df-421a-fec0-de7dfb82251e","executionInfo":{"status":"ok","timestamp":1574543753990,"user_tz":-120,"elapsed":894,"user":{"displayName":"Mina 3.Melek","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAWTZeaXL6pBID15v903jVhJLIYLmIkX1FgP2jL=s64","userId":"10444321559887690581"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["print('Train statistics:')\n","print('accuracy %s' % accuracy_score(y_pp.argmax(dim=1).cpu(), y_tt.argmax(dim=1).cpu()))\n","print(classification_report(y_tt.argmax(dim=1).cpu(), y_pp.argmax(dim=1).cpu(),target_names=list(int_category.values())))\n","print('Test statistics:')\n","print('accuracy %s' % accuracy_score(y_p.argmax(dim=1).cpu(), y_t.argmax(dim=1).cpu()))\n","print(classification_report(y_t.argmax(dim=1).cpu(), y_p.argmax(dim=1).cpu(),target_names=list(int_category.values())))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train statistics:\n","accuracy 0.7199223320305693\n","                precision    recall  f1-score   support\n","\n","          ARTS       0.44      0.45      0.44       297\n","ARTS & CULTURE       0.56      0.34      0.42       276\n","  BLACK VOICES       0.72      0.58      0.64       950\n","      BUSINESS       0.72      0.62      0.66      1199\n","       COLLEGE       0.57      0.50      0.53       218\n","        COMEDY       0.68      0.58      0.62      1023\n","         CRIME       0.74      0.77      0.75       678\n","CULTURE & ARTS       0.73      0.38      0.50       216\n","       DIVORCE       0.82      0.76      0.79       699\n","     EDUCATION       0.60      0.41      0.49       182\n"," ENTERTAINMENT       0.79      0.83      0.81      3177\n","   ENVIRONMENT       0.73      0.44      0.55       269\n","         FIFTY       0.53      0.28      0.37       274\n","  FOOD & DRINK       0.70      0.86      0.77      1267\n","     GOOD NEWS       0.52      0.38      0.44       282\n","         GREEN       0.53      0.56      0.54       497\n","HEALTHY LIVING       0.58      0.25      0.35      1309\n"," HOME & LIVING       0.83      0.88      0.86       862\n","        IMPACT       0.53      0.34      0.41       633\n"," LATINO VOICES       0.73      0.59      0.65       227\n","         MEDIA       0.75      0.66      0.70       582\n","         MONEY       0.63      0.55      0.59       332\n","     PARENTING       0.57      0.74      0.64      1733\n","       PARENTS       0.51      0.34      0.41       801\n","      POLITICS       0.82      0.88      0.85      6567\n","  QUEER VOICES       0.82      0.75      0.79      1187\n","      RELIGION       0.71      0.70      0.70       500\n","       SCIENCE       0.78      0.64      0.70       410\n","        SPORTS       0.85      0.84      0.85       968\n","         STYLE       0.67      0.54      0.60       470\n","STYLE & BEAUTY       0.86      0.88      0.87      1958\n","         TASTE       0.66      0.28      0.40       413\n","          TECH       0.67      0.71      0.69       382\n","        TRAVEL       0.84      0.88      0.86      1965\n","      WEDDINGS       0.87      0.83      0.85       740\n","    WEIRD NEWS       0.63      0.54      0.58       523\n","      WELLNESS       0.59      0.87      0.70      3586\n","         WOMEN       0.54      0.43      0.48       696\n","    WORLD NEWS       0.59      0.13      0.21       452\n","     WORLDPOST       0.64      0.78      0.70      1371\n","\n","      accuracy                           0.72     40171\n","     macro avg       0.68      0.59      0.62     40171\n","  weighted avg       0.72      0.72      0.71     40171\n","\n","Test statistics:\n","accuracy 0.5827338129496403\n","                precision    recall  f1-score   support\n","\n","          ARTS       0.28      0.25      0.26       264\n","ARTS & CULTURE       0.29      0.19      0.23       253\n","  BLACK VOICES       0.47      0.39      0.42       864\n","      BUSINESS       0.48      0.42      0.45      1174\n","       COLLEGE       0.44      0.41      0.42       229\n","        COMEDY       0.51      0.40      0.45      1089\n","         CRIME       0.49      0.56      0.52       697\n","CULTURE & ARTS       0.50      0.26      0.34       163\n","       DIVORCE       0.72      0.63      0.67       709\n","     EDUCATION       0.38      0.28      0.32       198\n"," ENTERTAINMENT       0.65      0.68      0.66      3240\n","   ENVIRONMENT       0.41      0.24      0.30       255\n","         FIFTY       0.33      0.13      0.19       276\n","  FOOD & DRINK       0.60      0.76      0.67      1228\n","     GOOD NEWS       0.32      0.28      0.30       264\n","         GREEN       0.40      0.37      0.38       540\n","HEALTHY LIVING       0.34      0.14      0.19      1407\n"," HOME & LIVING       0.68      0.74      0.71       840\n","        IMPACT       0.33      0.20      0.25       712\n"," LATINO VOICES       0.49      0.36      0.41       227\n","         MEDIA       0.51      0.44      0.47       570\n","         MONEY       0.39      0.32      0.35       317\n","     PARENTING       0.48      0.61      0.54      1733\n","       PARENTS       0.41      0.28      0.33       797\n","      POLITICS       0.72      0.80      0.76      6471\n","  QUEER VOICES       0.71      0.63      0.67      1288\n","      RELIGION       0.53      0.52      0.52       520\n","       SCIENCE       0.54      0.44      0.48       451\n","        SPORTS       0.70      0.61      0.65      1021\n","         STYLE       0.40      0.30      0.34       457\n","STYLE & BEAUTY       0.75      0.77      0.76      1895\n","         TASTE       0.37      0.15      0.21       447\n","          TECH       0.45      0.49      0.47       433\n","        TRAVEL       0.70      0.75      0.72      1935\n","      WEDDINGS       0.75      0.73      0.74       756\n","    WEIRD NEWS       0.35      0.28      0.31       541\n","      WELLNESS       0.50      0.76      0.61      3596\n","         WOMEN       0.36      0.30      0.33       675\n","    WORLD NEWS       0.28      0.04      0.07       428\n","     WORLDPOST       0.52      0.67      0.58      1211\n","\n","      accuracy                           0.58     40171\n","     macro avg       0.49      0.44      0.45     40171\n","  weighted avg       0.57      0.58      0.57     40171\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"cKhG2_LHwZ5c","colab_type":"text"},"source":["# 6. Save necessary files"]},{"cell_type":"code","metadata":{"id":"YNuEf1abIAcM","colab_type":"code","outputId":"59077664-7fdf-4240-dccc-08be7bd6d1d6","executionInfo":{"status":"ok","timestamp":1574543358874,"user_tz":-120,"elapsed":851,"user":{"displayName":"Mina 3.Melek","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAWTZeaXL6pBID15v903jVhJLIYLmIkX1FgP2jL=s64","userId":"10444321559887690581"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["modelspath=os.path.join(curDir,'ModelData','Pytorch_Model')\n","if not os.path.exists(modelspath):\n","    os.makedirs(modelspath)\n","torch.save(model.state_dict(), os.path.join(modelspath,'model_state_dict_v3_2.pth'))\n","# torch.save(model, os.path.join(modelspath,'model_v2.pth'))\n","print('Saved')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Saved\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ohLnzOpc6w9V","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rRfR6HeghCrD","colab_type":"code","colab":{}},"source":["# file_name=\"./model/glove_files/glove.840B.300d.txt\"\n","# with open(file_name,'r') as f:\n","#     word_vocab = set() # not using list to avoid duplicate entry\n","#     word2vector = {}\n","#     i=0\n","#     c=0\n","#     for line in f:\n","#         line_ = line.strip() #Remove white space\n","#         words_Vec = line_.split()\n","#         word_vocab.add(words_Vec[0])\n","#         try:\n","#             word2vector[words_Vec[0]] = np.array(words_Vec[1:],dtype=float)\n","#         except ValueError:\n","#             print(len(words_Vec), words_Vec[:len(words_Vec)-299])\n","#             if c == 5:\n","#                 print(i)\n","#                 print(words_Vec[1:])\n","#                 print(word2vector[words_Vec[0]])\n","#                 break\n","#             c += 1\n","#         i += 1\n","# print(\"Total Words in DataSet:\",len(word_vocab))\n","# print(len(word2vector))\n","# print(i-len(word2vector))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6xW_yzcIOMZS","colab_type":"code","colab":{}},"source":["# tsne = TSNE(n_components=2, random_state=0)\n","# # words =  list(embeddings_dict.keys())\n","# words = vocab\n","# # words = [\"branch\", \"twig\", \"finger\", \"hand\"]\n","# vectors = [w2v[word] for word in words]\n","# Y = tsne.fit_transform(vectors[:250])\n","# plt.figure(num=None, figsize=(16, 12), dpi=80, facecolor='w', edgecolor='k')\n","# plt.scatter(Y[:, 0], Y[:, 1])\n","\n","# for label, x, y in zip(words, Y[:, 0], Y[:, 1]):\n","#     plt.annotate(label, xy=(x, y), xytext=(0, 0), textcoords=\"offset points\")\n","# plt.show()"],"execution_count":0,"outputs":[]}]}